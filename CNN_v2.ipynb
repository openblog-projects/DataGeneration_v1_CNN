{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb576a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9e66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974452d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59868d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer=transforms.Compose([\n",
    "    #auf 150x150 Pixel skalieren\n",
    "    transforms.Resize((150,150)),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # pixelrange (of each colour channel) from 0-255 to 0-; datatyp of image is now tensor,not numpy\n",
    "    transforms.Normalize([0.5,0.5,0.5], #range from 0-1 to [-1,1]\n",
    "                        [0.5,0.5,0.5])\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e494079",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='/home/b1/CNN/DataGeneration_v1_CNN/dataset_1/train'\n",
    "test_path='/home/b1/CNN/DataGeneration_v1_CNN/dataset_1/test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    # batch size should fit to the CPU-power\n",
    "    batch_size=256, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    # batch size should fit to the CPU-power\n",
    "    batch_size=256, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3544339",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe973ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'noCar']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3435fe",
   "metadata": {},
   "outputs": [],
   "source": [
    " class ConvNet(nn.Module):\n",
    "        def __init__(self,num_classes=2):\n",
    "            super(ConvNet,self).__init__()\n",
    "            \n",
    "            # Input shape = (256,3,150,150); batch_size,numberOfChannels(rgb),height,width\n",
    "            self.\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
