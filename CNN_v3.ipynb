{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6615ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6729 201\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#################################################\n",
    "transformer=transforms.Compose([\n",
    "    #auf 150x150 Pixel skalieren\n",
    "    transforms.Resize((28,28)),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # pixelrange (of each colour channel) from 0-255 to 0-; datatyp of image is now tensor,not numpy\n",
    "    transforms.Normalize([0.5,0.5,0.5], #range from 0-1 to [-1,1]\n",
    "                        [0.5,0.5,0.5])\n",
    "]\n",
    ")\n",
    "##################################################################\n",
    "train_path='/home/b1/CNN/DataGeneration_v1_CNN/dataset_fullBackgr/train'\n",
    "test_path='/home/b1/CNN/DataGeneration_v1_CNN/dataset_fullBackgr/test'\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    # batch size should fit to the CPU-power\n",
    "    batch_size=8, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    # batch size should fit to the CPU-power\n",
    "    batch_size=8, shuffle=True\n",
    ")\n",
    "#########################################################\n",
    "class ConvNet(nn.Module):\n",
    "        def __init__(self,num_classes=2):\n",
    "            super(ConvNet,self).__init__()\n",
    "            \n",
    "            # Input shape = (256,3,150,150); batch_size,numberOfChannels(rgb),height,width\n",
    "            # in_channels= rgb\n",
    "           \n",
    "            self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "            # Output size after conv. filter ((width-kernel_size+2*Padding)/stride) +1\n",
    "            # new shape: (256,12,150,150)\n",
    "            self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "            # new shape: (256,12,150,150)\n",
    "            self.relu1=nn.ReLU()\n",
    "            # new shape: (256,12,150,150)\n",
    "            self.pool=nn.MaxPool2d(kernel_size=2) # reduce the image size with factor 2\n",
    "            # new shape: (256,12,75,75)\n",
    "            \n",
    "            \n",
    "            self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "            # new shape: (256,20,75,75)\n",
    "            self.relu2=nn.ReLU()\n",
    "            # new shape: (256,20,75,75)\n",
    "            \n",
    "            self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "            # new shape: (256,32,75,75)\n",
    "            self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "            # new shape: (256,32,75,75)\n",
    "            self.relu3=nn.ReLU()\n",
    "            # new shape: (256,32,75,75)\n",
    "            \n",
    "            # last layer:\n",
    "            self.fc=nn.Linear(in_features=32*14*14, out_features=num_classes)\n",
    "            \n",
    "            #Feed forward function\n",
    "        def forward(self,input):\n",
    "            output=self.conv1(input)\n",
    "            output=self.bn1(output)\n",
    "            output=self.relu1(output)\n",
    "                \n",
    "            output=self.pool(output)\n",
    "                \n",
    "            output=self.conv2(output)\n",
    "            output=self.relu2(output)\n",
    "                \n",
    "            output=self.conv3(output)\n",
    "            output=self.bn3(output)\n",
    "            output=self.relu3(output)\n",
    "                \n",
    "            # output will be in matrix form, with shape (256,32,75,75)\n",
    "                \n",
    "            output=output.view(-1,32*14*14) #last shape\n",
    "                \n",
    "            output=self.fc(output)\n",
    "                \n",
    "            return output\n",
    "###########################################################################\n",
    "model=ConvNet(num_classes=2).to(device)\n",
    "\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs=25\n",
    "#size of training/testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484ac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(0.0863) Train Accuracy: 0.9780056471986922 Test Accuracy: 0.7412935323383084\n",
      "Epoch: 1 Train Loss: tensor(0.0505) Train Accuracy: 0.9860306137613315 Test Accuracy: 0.6368159203980099\n",
      "Epoch: 2 Train Loss: tensor(0.0300) Train Accuracy: 0.9909347599940556 Test Accuracy: 0.6517412935323383\n",
      "Epoch: 3 Train Loss: tensor(0.0240) Train Accuracy: 0.9916778124535592 Test Accuracy: 0.7313432835820896\n",
      "Epoch: 4 Train Loss: tensor(0.0184) Train Accuracy: 0.993461138356368 Test Accuracy: 0.6567164179104478\n",
      "Epoch: 5 Train Loss: tensor(0.0167) Train Accuracy: 0.9930153068806657 Test Accuracy: 0.8706467661691543\n",
      "Epoch: 6 Train Loss: tensor(0.0078) Train Accuracy: 0.9973250111457869 Test Accuracy: 0.7412935323383084\n"
     ]
    }
   ],
   "source": [
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "\n",
    "    # Model evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    #save model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f39225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
